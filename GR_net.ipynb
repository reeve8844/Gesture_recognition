{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "c3294f0a7485f198b6f3089e5e440cb4834d8c28"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "b48bc7f8cf5c9fd721c8bed20084ad37c5caf706"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = './HGR/train/'\n",
    "TEST_DIR = './HGR/test/'\n",
    "IMG_SIZE = (240, 640)\n",
    "BATCH_SIZE = 8\n",
    "SEED = 1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "b48bc7f8cf5c9fd721c8bed20084ad37c5caf706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16000 images belonging to 10 classes.\n",
      "Found 4000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training generator\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_ds = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                             target_size=IMG_SIZE,\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             seed=SEED,\n",
    "                                             shuffle=True,\n",
    "                                             class_mode='categorical')\n",
    "\n",
    "# Test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_ds = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                           target_size=IMG_SIZE,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           seed=SEED,\n",
    "                                           shuffle=False,\n",
    "                                           class_mode='categorical')\n",
    "\n",
    "train_num = train_ds.samples\n",
    "test_num = test_ds.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "8380d9b52884e79366d1f57e1dcd20cd5c72f233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 240, 640, 32)      2432      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 120, 320, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 118, 318, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 59, 159, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 57, 157, 64)       18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 55, 155, 64)       36928     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 53, 153, 128)      73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 76, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 128)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 142,250\n",
      "Trainable params: 142,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod = Sequential()\n",
    "mod.add(Conv2D(filters=32, kernel_size=(5, 5), input_shape=(240, 640, 3), padding='same', activation = 'relu'))\n",
    "mod.add(MaxPool2D(2, 2))\n",
    "mod.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "mod.add(MaxPool2D(2, 2))\n",
    "mod.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "mod.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "mod.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
    "mod.add(MaxPool2D(2, 2))\n",
    "mod.add(GlobalAvgPool2D())\n",
    "mod.add(Dropout(0.3))\n",
    "\n",
    "mod.add(Flatten())\n",
    "mod.add(Activation('relu'))\n",
    "mod.add(Dense(10))\n",
    "mod.add(Activation('softmax'))\n",
    "\n",
    "mod.summary()\n",
    "\n",
    "mod.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "320f78e328c119bca7a7602135d8e8aeb49abdac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 2.1368 - accuracy: 0.2065\n",
      "Epoch 1: val_loss improved from inf to 1.66389, saving model to checkpoint/test1\\cp.ckpt\n",
      "2000/2000 [==============================] - 1848s 923ms/step - loss: 2.1368 - accuracy: 0.2065 - val_loss: 1.6639 - val_accuracy: 0.5422\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.6240 - accuracy: 0.4251\n",
      "Epoch 2: val_loss improved from 1.66389 to 1.01045, saving model to checkpoint/test1\\cp.ckpt\n",
      "2000/2000 [==============================] - 1914s 957ms/step - loss: 1.6240 - accuracy: 0.4251 - val_loss: 1.0104 - val_accuracy: 0.6407\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.2515 - accuracy: 0.5596\n",
      "Epoch 3: val_loss improved from 1.01045 to 0.75413, saving model to checkpoint/test1\\cp.ckpt\n",
      "2000/2000 [==============================] - 1962s 981ms/step - loss: 1.2515 - accuracy: 0.5596 - val_loss: 0.7541 - val_accuracy: 0.8037\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0590 - accuracy: 0.6306\n",
      "Epoch 4: val_loss improved from 0.75413 to 0.69295, saving model to checkpoint/test1\\cp.ckpt\n",
      "2000/2000 [==============================] - 1955s 977ms/step - loss: 1.0590 - accuracy: 0.6306 - val_loss: 0.6929 - val_accuracy: 0.8085\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.9558 - accuracy: 0.6663\n",
      "Epoch 5: val_loss did not improve from 0.69295\n",
      "2000/2000 [==============================] - 1943s 971ms/step - loss: 0.9558 - accuracy: 0.6663 - val_loss: 0.8712 - val_accuracy: 0.8583\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "checkpoint_path = \"checkpoint/test1/cp.ckpt\"\n",
    "\n",
    "# mod.load_weights(checkpoint_path)\n",
    "\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                              save_weights_only=True,\n",
    "                              save_best_only=True,\n",
    "                              mode='min',\n",
    "                              verbose=1)\n",
    "\n",
    "history = mod.fit(train_ds,\n",
    "                              steps_per_epoch=train_num // BATCH_SIZE,\n",
    "                              epochs=EPOCHS,\n",
    "                              validation_data=test_ds,\n",
    "                              validation_steps=test_num // BATCH_SIZE,\n",
    "                              callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 99s 199ms/step - loss: 0.6929 - accuracy: 0.8085\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"checkpoint/test1/cp.ckpt\"\n",
    "\n",
    "mod.load_weights(checkpoint_path)\n",
    "\n",
    "mod.evaluate(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "mod.save('GR_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tf.keras.models.load_model('GR_net.h5')\n",
    "\n",
    "mod.evaluate(test_ds, batch_size=BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "convolutional-neural-networks",
   "graded_item_id": "bwbJV",
   "launcher_item_id": "0TkXB"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
